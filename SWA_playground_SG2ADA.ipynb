{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SWA-playground-SG2ADA.ipynb",
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dvschultz/ml-art-colabs/blob/master/SWA_playground_SG2ADA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHwfdgwfnXcn"
      },
      "source": [
        "Modified port of @arfafaxâ€™s notebook [here](https://github.com/arfafax/StyleGAN2_experiments/blob/master/StyleGAN2%20Network%20Interpolation.ipynb) to work with stylegan2-ada"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEYEmB4_jz4g"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "\n",
        "!git clone https://github.com/dvschultz/stylegan2-ada\n",
        "%cd stylegan2-ada"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlKAtSGpZH0C"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMnPeiiAZKD5"
      },
      "source": [
        "!gdown --id 12JuWv5OAqInDajEtyk8C9Xy7H5kMOw89\n",
        "!gdown --id 1FbltaJujVl5V9LZoX9-wcZFTlqCbWNcz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5PWVTd4h7zA"
      },
      "source": [
        "import ipywidgets as widgets\n",
        "#import pretrained_networks\n",
        "import PIL.Image\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "import dnnlib\n",
        "import dnnlib.tflib as tflib\n",
        "\n",
        "tflib.init_tf()\n",
        "\n",
        "src_model = './network-snapshot-000448.pkl' #floralmag\n",
        "dst_model = './network-snapshot-000042.pkl' #ladiescrop\n",
        "\n",
        "print('Loading source network from \"%s\"...' % src_model)\n",
        "with dnnlib.util.open_url(src_model) as fp:\n",
        "    _G, _D, Gs = pickle.load(fp)\n",
        "print('Loading destination network from \"%s\"...' % dst_model)\n",
        "with dnnlib.util.open_url(dst_model) as fp:\n",
        "    _Gd, _Dd, Gsd = pickle.load(fp)\n",
        "\n",
        "bGs = Gs.clone()\n",
        "\n",
        "Gs_syn_kwargs = dnnlib.EasyDict()\n",
        "batch_size = 1\n",
        "Gs_syn_kwargs.output_transform = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n",
        "Gs_syn_kwargs.randomize_noise = True\n",
        "Gs_syn_kwargs.minibatch_size = batch_size\n",
        "\n",
        "noise_vars = [var for name, var in Gs.components.synthesis.vars.items() if name.startswith('noise')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jp8G9JCjjPfd"
      },
      "source": [
        "from dnnlib.tflib import tfutil\n",
        "def weighted_average(src_net, dst_net, t):\n",
        "    names = []\n",
        "    for name in src_net.trainables.keys():\n",
        "        if name not in src_net.trainables:\n",
        "            print(\"Not restoring (not present):     {}\".format(name))\n",
        "        elif dst_net.trainables[name].shape != src_net.trainables[name].shape:\n",
        "            print(\"Not restoring (different shape): {}\".format(name))\n",
        "\n",
        "        if name in src_net.trainables and dst_net.trainables[name].shape == src_net.trainables[name].shape:\n",
        "            names.append(name)\n",
        "\n",
        "    tfutil.set_vars(tfutil.run({bGs.vars[name]: (t*dst_net.vars[name] + (1-t)*src_net.vars[name]) for name in names}))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iX0xpdc8jUOB"
      },
      "source": [
        "seed = widgets.IntSlider(min=0, max=100000, step=1, value=0, description='Seed: ', continuous_update=False)\n",
        "scale = widgets.FloatSlider(min=0, max=5, step=0.01, value=1, description='Scale: ', continuous_update=False)\n",
        "truncation = widgets.FloatSlider(min=-2, max=2, step=0.1, value=1, description='Truncation: ', continuous_update=False)\n",
        "blending = widgets.FloatSlider(min=0, max=1, step=0.01, value=0, description='Blending: ', continuous_update=False)\n",
        "\n",
        "bot_box = widgets.HBox([seed, scale, truncation, blending])\n",
        "ui = widgets.VBox([bot_box])\n",
        "\n",
        "def display_sample(seed, scale, truncation, blending):\n",
        "    weighted_average(Gs, Gsd, blending)\n",
        "    \n",
        "    Gs_kwargs = {\n",
        "        'output_transform': dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True),\n",
        "        'randomize_noise': False\n",
        "    }\n",
        "    if truncation is not None:\n",
        "        Gs_kwargs['truncation_psi'] = truncation\n",
        "    \n",
        "    rnd = np.random.RandomState(seed)\n",
        "    tflib.set_vars({var: rnd.randn(*var.shape.as_list()) for var in noise_vars}) # [height, width]\n",
        "    \n",
        "    batch_size = 1\n",
        "    all_seeds = [seed] * batch_size\n",
        "    all_z = np.stack([np.random.RandomState(seed).randn(*bGs.input_shape[1:]) for seed in all_seeds]) # [minibatch, component]\n",
        "    all_w = bGs.components.mapping.run(scale*all_z, None) # [minibatch, layer, component]\n",
        "    if truncation != 1:\n",
        "        w_avg = bGs.get_var('dlatent_avg')\n",
        "        all_w = w_avg + (all_w - w_avg) * truncation # [minibatch, layer, component]\n",
        "    all_images = bGs.components.synthesis.run(all_w, **Gs_syn_kwargs)\n",
        "    #save image and display\n",
        "    display(PIL.Image.fromarray(np.median(all_images, axis=0).astype(np.uint8)))\n",
        "\n",
        "out = widgets.interactive_output(display_sample, {'seed': seed, 'scale': scale, 'truncation': truncation, 'blending': blending})\n",
        "\n",
        "display(ui, out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_lLEjme8mH1"
      },
      "source": [
        "%cd ../\n",
        "%mkdir 17258\n",
        "%cd stylegan2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyjnsbuN1jAQ"
      },
      "source": [
        "\n",
        "def save_sample(seed, scale, truncation, blending):\n",
        "    weighted_average(Gs, Gsd, blending)\n",
        "    \n",
        "    Gs_kwargs = dnnlib.EasyDict()\n",
        "    Gs_kwargs.output_transform = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n",
        "    Gs_kwargs.randomize_noise = False\n",
        "    if truncation is not None:\n",
        "        Gs_kwargs.truncation_psi = truncation\n",
        "    rnd = np.random.RandomState(seed)\n",
        "    tflib.set_vars({var: rnd.randn(*var.shape.as_list()) for var in noise_vars}) # [height, width]\n",
        "    \n",
        "    batch_size = 1\n",
        "    all_seeds = [seed] * batch_size\n",
        "    all_z = np.stack([np.random.RandomState(seed).randn(*bGs.input_shape[1:]) for seed in all_seeds]) # [minibatch, component]\n",
        "    all_w = bGs.components.mapping.run(scale*all_z, None) # [minibatch, layer, component]\n",
        "    if truncation != 1:\n",
        "        w_avg = bGs.get_var('dlatent_avg')\n",
        "        all_w = w_avg + (all_w - w_avg) * truncation # [minibatch, layer, component]\n",
        "    all_images = bGs.components.synthesis.run(all_w, **Gs_syn_kwargs)\n",
        "    #save image and display\n",
        "    #display(PIL.Image.fromarray(np.median(all_images, axis=0).astype(np.uint8)))\n",
        "    PIL.Image.fromarray(np.median(all_images, axis=0).astype(np.uint8)).save(\"/content/17258/%.2f.png\" % blending)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFDktf5B82z_"
      },
      "source": [
        "%cd ../17258\n",
        "for i in np.arange(0, 1.0, 0.01):\n",
        "  save_sample(17528,1.0,0.1,i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzOlsg1C-bSs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}