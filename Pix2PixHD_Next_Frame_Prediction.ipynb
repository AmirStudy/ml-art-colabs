{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pix2PixHD Next Frame Prediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dvschultz/ml-art-colabs/blob/master/Pix2PixHD_Next_Frame_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXoBaXRDKuMV",
        "colab_type": "text"
      },
      "source": [
        "#Next Frame Prediction using Pix2PixHD\n",
        "\n",
        "By Derrick Schultz\n",
        "\n",
        "Forked repo and tutorial based on [JC Testud’s excellent repo and Medium](https://medium.com/@jctestud/video-generation-with-pix2pix-aed5b1b69f57) article."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfOexYWJX3Pt",
        "colab_type": "text"
      },
      "source": [
        "## Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K--AsrIzpH58",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "32136ece-a6c0-4d4b-ce1a-cf3a58e5b789"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUvLbCJtLqaV",
        "colab_type": "text"
      },
      "source": [
        "## Install libraries and dependencies\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3dczlxhXwe6",
        "colab_type": "text"
      },
      "source": [
        "### Run this cell if you haven’t previously install Pix2PixHD in your Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQbRsmWdvjUo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5c13ff37-6ebf-40b1-9371-5bb3fca428b8"
      },
      "source": [
        "%cd /content/drive/My\\ Drive\n",
        "!mkdir nfp-colab\n",
        "%cd nfp-colab\n",
        "!git clone -b video https://github.com/dvschultz/pix2pixHD.git\n",
        "!pip install dominate\n",
        "%cd pix2pixHD/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yDOMtTH42xl",
        "colab_type": "text"
      },
      "source": [
        "### Run this cell if you’ve already installed Pix2PixHD in Google Drive before"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V94ah70BxPUn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "cf08243a-eb12-4fe2-f0d3-9f7fdd89cad8"
      },
      "source": [
        "%cd /content/drive/My\\ Drive/nfp-colab/pix2pixHD/\n",
        "# !git pull\n",
        "!pip install dominate\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/nfp-colab/pix2pixHD\n",
            "Requirement already satisfied: dominate in /usr/local/lib/python3.6/dist-packages (2.5.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzLGf05WXMFV",
        "colab_type": "text"
      },
      "source": [
        "## Extract frames from video\n",
        "\n",
        "Upload a video to either Colab or Google Drive.\n",
        "\n",
        "* `-video` is the path to the video file\n",
        "* `-name` should be a unique name (think of it like a project name)\n",
        "* `-width` and `-height` **must** to be a multiple of 32\n",
        "* `-p2pdir` leave as `.` unless you know it shouldn’t be that ;)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWRL2ty6N9LD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "8a9fc059-0bf3-4258-d982-4fecabbf7126"
      },
      "source": [
        "!python extract_frames.py -video /content/cuttlefish1.mov -name cuttlefish1 -p2pdir . -width 1280 -height 736"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "creating the dataset structure\n",
            "ffmpeg -v 16 -i /content/cuttlefish1.mov -q:v 2 -vf \"scale=iw*736/ih:736, crop=1280:736\" /content/drive/My\\ Drive/nfp-colab/pix2pixHD/datasets/cuttlefish1/train_frames/frame-%06d.jpg -hide_banner\n",
            "extracting the frames\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qL9BZkBA_QRR",
        "colab_type": "text"
      },
      "source": [
        "## Train your model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4X7qahzMX05u",
        "colab_type": "text"
      },
      "source": [
        "### Initial training\n",
        "\n",
        "Note: if you have a large dataset, this may timeout initially (`ValueError: __len__() should return >= 0`). Give it a minute or two and run it again.\n",
        "\n",
        "*   `--name` should be a unique name (think of it like a project name). For your sanity I recommend using the same `-name` as above.\n",
        "*   `--dataroot` should point to your dataset. This will usually be in `./datasets/[your project name]`\n",
        "\n",
        " \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzHBGVnUKEzE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5dc7fa21-47ce-4e75-f96b-012943f3f7d4"
      },
      "source": [
        "!python train_video.py --name cuttlefish1 --dataroot ./datasets/cuttlefish1/ --save_epoch_freq 1 #--continue_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------ Options -------------\n",
            "batchSize: 1\n",
            "beta1: 0.5\n",
            "checkpoints_dir: ./checkpoints\n",
            "continue_train: False\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cuttlefish1/\n",
            "debug: False\n",
            "display_freq: 100\n",
            "display_winsize: 512\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "fps: 24.0\n",
            "gpu_ids: [0]\n",
            "heat_seeking_lvl: 0\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: True\n",
            "label_feat: False\n",
            "label_nc: 35\n",
            "lambda_feat: 10.0\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "load_pretrain: \n",
            "local_rank: 0\n",
            "lr: 0.0002\n",
            "max_dataset_size: inf\n",
            "model: pix2pixHD\n",
            "nThreads: 2\n",
            "n_blocks_global: 9\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 4\n",
            "n_layers_D: 3\n",
            "n_local_enhancers: 1\n",
            "name: cuttlefish1\n",
            "ndf: 64\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter: 100\n",
            "niter_decay: 100\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_ganFeat_loss: False\n",
            "no_html: False\n",
            "no_instance: False\n",
            "no_lsgan: False\n",
            "no_vgg_loss: False\n",
            "norm: instance\n",
            "num_D: 2\n",
            "output_nc: 3\n",
            "phase: train\n",
            "pool_size: 0\n",
            "print_freq: 100\n",
            "pstart: 1\n",
            "pstop: 1\n",
            "resize_or_crop: scale_width\n",
            "save_epoch_freq: 1\n",
            "save_latest_freq: 1000\n",
            "scheduled_sampling: False\n",
            "serial_batches: False\n",
            "ss_recursion_prob: 0.2\n",
            "start_from: video\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "verbose: False\n",
            "video_mode: False\n",
            "which_epoch: latest\n",
            "zoom_lvl: 0\n",
            "-------------- End ----------------\n",
            "CustomDatasetDataLoader\n",
            "dataset [FrameDataset] was created\n",
            "FrameDataset initialized from: ./datasets/cuttlefish1/train_frames\n",
            "contains 150 frames, 149 consecutive pairs\n",
            "#training images = 149\n",
            "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n",
            "100% 548M/548M [00:02<00:00, 242MB/s]\n",
            "create web directory ./checkpoints/cuttlefish1/web...\n",
            "(epoch: 1, iters: 100, time: 1.394) G_GAN: 0.640 G_GAN_Feat: 2.642 G_VGG: 3.193 D_real: 0.469 D_fake: 0.592 \n",
            "End of epoch 1 / 200 \t Time Taken: 207 sec\n",
            "saving the model at the end of epoch 1, iters 149\n",
            "(epoch: 2, iters: 51, time: 1.467) G_GAN: 0.881 G_GAN_Feat: 3.104 G_VGG: 1.791 D_real: 0.404 D_fake: 0.383 \n",
            "End of epoch 2 / 200 \t Time Taken: 207 sec\n",
            "saving the model at the end of epoch 2, iters 298\n",
            "(epoch: 3, iters: 2, time: 1.461) G_GAN: 1.098 G_GAN_Feat: 4.043 G_VGG: 1.656 D_real: 0.194 D_fake: 0.304 \n",
            "(epoch: 3, iters: 102, time: 1.390) G_GAN: 1.334 G_GAN_Feat: 3.595 G_VGG: 1.696 D_real: 0.181 D_fake: 0.167 \n",
            "End of epoch 3 / 200 \t Time Taken: 207 sec\n",
            "saving the model at the end of epoch 3, iters 447\n",
            "(epoch: 4, iters: 53, time: 1.469) G_GAN: 0.454 G_GAN_Feat: 1.835 G_VGG: 1.458 D_real: 0.316 D_fake: 0.696 \n",
            "End of epoch 4 / 200 \t Time Taken: 207 sec\n",
            "saving the model at the end of epoch 4, iters 596\n",
            "(epoch: 5, iters: 4, time: 1.459) G_GAN: 1.555 G_GAN_Feat: 11.103 G_VGG: 8.495 D_real: 0.849 D_fake: 0.223 \n",
            "(epoch: 5, iters: 104, time: 1.390) G_GAN: 0.708 G_GAN_Feat: 2.551 G_VGG: 1.352 D_real: 0.177 D_fake: 0.546 \n",
            "End of epoch 5 / 200 \t Time Taken: 207 sec\n",
            "saving the model at the end of epoch 5, iters 745\n",
            "(epoch: 6, iters: 55, time: 1.468) G_GAN: 1.215 G_GAN_Feat: 3.704 G_VGG: 1.350 D_real: 0.100 D_fake: 0.155 \n",
            "End of epoch 6 / 200 \t Time Taken: 207 sec\n",
            "saving the model at the end of epoch 6, iters 894\n",
            "(epoch: 7, iters: 6, time: 1.471) G_GAN: 1.097 G_GAN_Feat: 3.496 G_VGG: 1.281 D_real: 0.078 D_fake: 0.285 \n",
            "(epoch: 7, iters: 106, time: 1.390) G_GAN: 0.795 G_GAN_Feat: 2.355 G_VGG: 1.308 D_real: 0.445 D_fake: 0.559 \n",
            "saving the latest model (epoch 7, total_steps 1000)\n",
            "End of epoch 7 / 200 \t Time Taken: 212 sec\n",
            "saving the model at the end of epoch 7, iters 1043\n",
            "(epoch: 8, iters: 57, time: 1.463) G_GAN: 1.834 G_GAN_Feat: 4.383 G_VGG: 1.245 D_real: 0.246 D_fake: 0.091 \n",
            "End of epoch 8 / 200 \t Time Taken: 207 sec\n",
            "saving the model at the end of epoch 8, iters 1192\n",
            "(epoch: 9, iters: 8, time: 1.458) G_GAN: 1.395 G_GAN_Feat: 3.773 G_VGG: 1.236 D_real: 0.391 D_fake: 0.186 \n",
            "(epoch: 9, iters: 108, time: 1.389) G_GAN: 1.237 G_GAN_Feat: 3.363 G_VGG: 1.211 D_real: 0.170 D_fake: 0.216 \n",
            "End of epoch 9 / 200 \t Time Taken: 207 sec\n",
            "saving the model at the end of epoch 9, iters 1341\n",
            "(epoch: 10, iters: 59, time: 1.469) G_GAN: 1.465 G_GAN_Feat: 3.516 G_VGG: 1.267 D_real: 0.134 D_fake: 0.212 \n",
            "End of epoch 10 / 200 \t Time Taken: 207 sec\n",
            "saving the model at the end of epoch 10, iters 1490\n",
            "(epoch: 11, iters: 10, time: 1.459) G_GAN: 1.512 G_GAN_Feat: 3.119 G_VGG: 1.227 D_real: 0.457 D_fake: 0.141 \n",
            "(epoch: 11, iters: 110, time: 1.389) G_GAN: 1.567 G_GAN_Feat: 4.493 G_VGG: 1.177 D_real: 0.025 D_fake: 0.070 \n",
            "End of epoch 11 / 200 \t Time Taken: 207 sec\n",
            "saving the model at the end of epoch 11, iters 1639\n",
            "(epoch: 12, iters: 61, time: 1.460) G_GAN: 1.137 G_GAN_Feat: 2.939 G_VGG: 1.165 D_real: 0.138 D_fake: 0.212 \n",
            "End of epoch 12 / 200 \t Time Taken: 207 sec\n",
            "saving the model at the end of epoch 12, iters 1788\n",
            "(epoch: 13, iters: 12, time: 1.460) G_GAN: 2.374 G_GAN_Feat: 6.649 G_VGG: 1.300 D_real: 0.411 D_fake: 0.057 \n",
            "(epoch: 13, iters: 112, time: 1.389) G_GAN: 1.507 G_GAN_Feat: 3.823 G_VGG: 1.126 D_real: 0.274 D_fake: 0.135 \n",
            "End of epoch 13 / 200 \t Time Taken: 207 sec\n",
            "saving the model at the end of epoch 13, iters 1937\n",
            "(epoch: 14, iters: 63, time: 1.459) G_GAN: 2.277 G_GAN_Feat: 6.757 G_VGG: 1.223 D_real: 0.047 D_fake: 0.072 \n",
            "saving the latest model (epoch 14, total_steps 2000)\n",
            "End of epoch 14 / 200 \t Time Taken: 211 sec\n",
            "saving the model at the end of epoch 14, iters 2086\n",
            "(epoch: 15, iters: 14, time: 1.470) G_GAN: 0.671 G_GAN_Feat: 2.580 G_VGG: 1.099 D_real: 0.471 D_fake: 0.589 \n",
            "(epoch: 15, iters: 114, time: 1.389) G_GAN: 1.488 G_GAN_Feat: 4.411 G_VGG: 1.160 D_real: 0.108 D_fake: 0.099 \n",
            "End of epoch 15 / 200 \t Time Taken: 207 sec\n",
            "saving the model at the end of epoch 15, iters 2235\n",
            "(epoch: 16, iters: 65, time: 1.478) G_GAN: 1.052 G_GAN_Feat: 3.786 G_VGG: 1.126 D_real: 0.202 D_fake: 0.493 \n",
            "End of epoch 16 / 200 \t Time Taken: 207 sec\n",
            "saving the model at the end of epoch 16, iters 2384\n",
            "(epoch: 17, iters: 16, time: 1.461) G_GAN: 2.758 G_GAN_Feat: 5.111 G_VGG: 1.104 D_real: 0.254 D_fake: 0.106 \n",
            "(epoch: 17, iters: 116, time: 1.389) G_GAN: 1.429 G_GAN_Feat: 4.802 G_VGG: 1.177 D_real: 0.066 D_fake: 0.087 \n",
            "End of epoch 17 / 200 \t Time Taken: 207 sec\n",
            "saving the model at the end of epoch 17, iters 2533\n",
            "(epoch: 18, iters: 67, time: 1.467) G_GAN: 0.849 G_GAN_Feat: 3.029 G_VGG: 1.111 D_real: 0.302 D_fake: 0.433 \n",
            "End of epoch 18 / 200 \t Time Taken: 207 sec\n",
            "saving the model at the end of epoch 18, iters 2682\n",
            "(epoch: 19, iters: 18, time: 1.457) G_GAN: 3.292 G_GAN_Feat: 6.249 G_VGG: 1.151 D_real: 0.197 D_fake: 0.177 \n",
            "(epoch: 19, iters: 118, time: 1.389) G_GAN: 1.328 G_GAN_Feat: 3.682 G_VGG: 1.081 D_real: 0.054 D_fake: 0.168 \n",
            "End of epoch 19 / 200 \t Time Taken: 207 sec\n",
            "saving the model at the end of epoch 19, iters 2831\n",
            "(epoch: 20, iters: 69, time: 1.473) G_GAN: 1.143 G_GAN_Feat: 4.095 G_VGG: 1.085 D_real: 0.068 D_fake: 0.188 \n",
            "End of epoch 20 / 200 \t Time Taken: 207 sec\n",
            "saving the model at the end of epoch 20, iters 2980\n",
            "(epoch: 21, iters: 20, time: 1.468) G_GAN: 0.865 G_GAN_Feat: 2.954 G_VGG: 1.098 D_real: 0.354 D_fake: 0.399 \n",
            "saving the latest model (epoch 21, total_steps 3000)\n",
            "(epoch: 21, iters: 120, time: 1.389) G_GAN: 2.278 G_GAN_Feat: 3.392 G_VGG: 1.066 D_real: 0.804 D_fake: 0.039 \n",
            "End of epoch 21 / 200 \t Time Taken: 211 sec\n",
            "saving the model at the end of epoch 21, iters 3129\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GDg3CeW_1TD",
        "colab_type": "text"
      },
      "source": [
        "### Continue Training\n",
        "To pick up from a previous training session run the same command you ran to start with and append `--continue_train` to the end of the command."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5q3dE9S_5eg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python train_video.py --name cuttlefish1 --dataroot ./datasets/cuttlefish1/ --save_epoch_freq 1 --continue_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jly_3OyBoGg2",
        "colab_type": "text"
      },
      "source": [
        "#Generating Videos\n",
        "\n",
        "To generate a video from your completed model, run the `generate_video.py` script. I recommend keeping the `--name` and `--dataroot` arguments the same.\n",
        "\n",
        "There are a number of additional arguments you’ll need to include in this command:\n",
        "\n",
        "\n",
        "*   `--fps` frame rate for your video\n",
        "*   `--how_many` how many frames you want to create (this + fps = video length)\n",
        "*   `--which_epoch` which epoch you want to generate videos from (note: if you choose `133` but there’s no epoch 133 model file, this will throw an error)\n",
        "*   `--start_from` by default your video will start predicting images from the 60th frame of your training set. You can pass in the path to a different frame to have it start from that frame\n",
        "\n",
        "I recommend playing with both the `--which_epoch` and `--start_from` arguments as you can get dramatically different results by changing in the inputs here.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INVUtG-pt_F6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python generate_video.py --name cuttlefish1 --dataroot ./datasets/cuttlefish1/ --fps 24 --how_many 600 --which_epoch latest "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiaLMDmdDG3t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "2191c96c-03fa-48e1-8013-ab130e6df9e0"
      },
      "source": [
        "import os\n",
        "\n",
        "def processFolder(folder, epoch = 10, frameCount = 240, skipCount = 1):\n",
        "  files = os.listdir(folder)\n",
        "\n",
        "  count = 0\n",
        "  for f in files:\n",
        "    \n",
        "    if (count % skipCount == 0):\n",
        "      print(f)\n",
        "      if epoch == 'latest':\n",
        "        command = 'python generate_video.py --name glitch_white_circle --dataroot ./datasets/glitch-circle-white_dataset/ --fps 60 --how_many %i --which_epoch latest --start_from %s/%s' % ( frameCount, folder, f)\n",
        "      else:\n",
        "        command = 'python generate_video.py --name glitch_white_circle --dataroot ./datasets/glitch-circle-white_dataset/ --fps 24 --how_many %i --which_epoch %i --start_from %s/%s' % ( frameCount, epoch, folder, f)\n",
        "      os.system(command)\n",
        "    count += 1\n",
        "\n",
        "processFolder('./datasets/fuck-white/train_frames',1,600,3050)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "frame-018504.jpg\n",
            "frame-015525.jpg\n",
            "frame-012746.jpg\n",
            "frame-009603.jpg\n",
            "frame-006972.jpg\n",
            "frame-004082.jpg\n",
            "frame-001186.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}