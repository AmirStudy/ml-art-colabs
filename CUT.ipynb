{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CUT.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyODUur74gUOw2OOhDoOSoJL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dvschultz/ml-art-colabs/blob/master/CUT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVR4bEt9Ptel",
        "colab_type": "text"
      },
      "source": [
        "#CUT\n",
        "This new model uses contrastive learning (the hot technique of the moment) to better train unaligned image to image translation (i.e. CycleGAN)\n",
        "\n",
        "[GitHub](https://github.com/taesungp/contrastive-unpaired-translation)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHt7jlAPKw2l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853
        },
        "outputId": "7f708512-1901-4639-8aa8-fef4b340419f"
      },
      "source": [
        "!git clone https://github.com/taesungp/contrastive-unpaired-translation CUT\n",
        "!pip install dominate visdom GPUtil\n",
        "%cd CUT"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'CUT'...\n",
            "remote: Enumerating objects: 178, done.\u001b[K\n",
            "remote: Counting objects: 100% (178/178), done.\u001b[K\n",
            "remote: Compressing objects: 100% (131/131), done.\u001b[K\n",
            "remote: Total 178 (delta 77), reused 142 (delta 44), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (178/178), 17.04 MiB | 7.90 MiB/s, done.\n",
            "Resolving deltas: 100% (77/77), done.\n",
            "Collecting dominate\n",
            "  Downloading https://files.pythonhosted.org/packages/4f/e6/794a119963b7cfe4bd41177c8f9d4195fe901652f04189fbd2edf513c7b2/dominate-2.5.1-py2.py3-none-any.whl\n",
            "Collecting visdom\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c9/75/e078f5a2e1df7e0d3044749089fc2823e62d029cc027ed8ae5d71fafcbdc/visdom-0.1.8.9.tar.gz (676kB)\n",
            "\u001b[K     |████████████████████████████████| 686kB 5.8MB/s \n",
            "\u001b[?25hCollecting GPUtil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Requirement already satisfied: numpy>=1.8 in /usr/local/lib/python3.6/dist-packages (from visdom) (1.18.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from visdom) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from visdom) (2.23.0)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.6/dist-packages (from visdom) (5.1.1)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.6/dist-packages (from visdom) (19.0.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from visdom) (1.15.0)\n",
            "Collecting jsonpatch\n",
            "  Downloading https://files.pythonhosted.org/packages/4f/d0/34b0f59ac08de9c1e07876cfecd80aec650600177b4bd445124c755499a7/jsonpatch-1.26-py2.py3-none-any.whl\n",
            "Collecting torchfile\n",
            "  Downloading https://files.pythonhosted.org/packages/91/af/5b305f86f2d218091af657ddb53f984ecbd9518ca9fe8ef4103a007252c9/torchfile-0.1.0.tar.gz\n",
            "Collecting websocket-client\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/5f/f61b420143ed1c8dc69f9eaec5ff1ac36109d52c80de49d66e0c36c3dfdf/websocket_client-0.57.0-py2.py3-none-any.whl (200kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 19.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from visdom) (7.0.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->visdom) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->visdom) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->visdom) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->visdom) (2020.6.20)\n",
            "Collecting jsonpointer>=1.9\n",
            "  Downloading https://files.pythonhosted.org/packages/18/b0/a80d29577c08eea401659254dfaed87f1af45272899e1812d7e01b679bc5/jsonpointer-2.0-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: visdom, GPUtil, torchfile\n",
            "  Building wheel for visdom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for visdom: filename=visdom-0.1.8.9-cp36-none-any.whl size=655250 sha256=dc830a9cc49dbbfffaa303aabbdbaac123436d40e77955b018f4752b20bd0cc6\n",
            "  Stored in directory: /root/.cache/pip/wheels/70/19/a7/6d589ed967f4dfefd33bc166d081257bd4ed0cb618dccfd62a\n",
            "  Building wheel for GPUtil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for GPUtil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7413 sha256=4917d689299a3d09c25fe0c9505026c7fc832a50636046e01b435148bd364be6\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "  Building wheel for torchfile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchfile: filename=torchfile-0.1.0-cp36-none-any.whl size=5712 sha256=50205ce9c5d33000b88327222b8d6ad91520d1289876da30e61a91fb11131791\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/c3/d6/9a1cc8f3a99a0fc1124cae20153f36af59a6e683daca0a0814\n",
            "Successfully built visdom GPUtil torchfile\n",
            "Installing collected packages: dominate, jsonpointer, jsonpatch, torchfile, websocket-client, visdom, GPUtil\n",
            "Successfully installed GPUtil-1.4.0 dominate-2.5.1 jsonpatch-1.26 jsonpointer-2.0 torchfile-0.1.0 visdom-0.1.8.9 websocket-client-0.57.0\n",
            "/content/CUT\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1tdZoGaMOGf",
        "colab_type": "text"
      },
      "source": [
        "## Train\n",
        "Create a folder in `./datasets` and put two folders inside it. `trainA` should contain images from one domain and `trainB` should contain images from another domain. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRI0XL6xK386",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#example: download the russian blue cats to grumpy cats dataset\n",
        "!bash ./datasets/download_cut_dataset.sh grumpifycat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_npjQWxMjkr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_path = './datasets/grumpifycat'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WEJ3xy9K8ck",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d267181d-bea3-46e4-95e3-f6c840f34072"
      },
      "source": [
        "!python train.py --dataroot ./datasets/grumpifycat --name grumpycat_CUT --CUT_mode CUT"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------- Options ---------------\n",
            "                 CUT_mode: CUT                           \n",
            "               batch_size: 1                             \n",
            "                    beta1: 0.5                           \n",
            "                    beta2: 0.999                         \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "           continue_train: False                         \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ./datasets/grumpifycat        \t[default: placeholder]\n",
            "             dataset_mode: unaligned                     \n",
            "                direction: AtoB                          \n",
            "              display_env: main                          \n",
            "             display_freq: 400                           \n",
            "               display_id: None                          \n",
            "            display_ncols: 4                             \n",
            "             display_port: 8097                          \n",
            "           display_server: http://localhost              \n",
            "          display_winsize: 256                           \n",
            "               easy_label: experiment_name               \n",
            "                    epoch: latest                        \n",
            "              epoch_count: 1                             \n",
            "          evaluation_freq: 5000                          \n",
            "        flip_equivariance: False                         \n",
            "                 gan_mode: lsgan                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: xavier                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: True                          \t[default: None]\n",
            "               lambda_GAN: 1.0                           \n",
            "               lambda_NCE: 1.0                           \n",
            "                load_size: 286                           \n",
            "                       lr: 0.0002                        \n",
            "           lr_decay_iters: 50                            \n",
            "                lr_policy: linear                        \n",
            "         max_dataset_size: inf                           \n",
            "                    model: cut                           \n",
            "                 n_epochs: 200                           \n",
            "           n_epochs_decay: 200                           \n",
            "               n_layers_D: 3                             \n",
            "                     name: grumpycat_CUT                 \t[default: experiment_name]\n",
            "                    nce_T: 0.07                          \n",
            "                  nce_idt: True                          \n",
            "               nce_layers: 0,4,8,12,16                   \n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netF: mlp_sample                    \n",
            "                  netF_nc: 256                           \n",
            "                     netG: resnet_9blocks                \n",
            "                      ngf: 64                            \n",
            "             no_antialias: False                         \n",
            "          no_antialias_up: False                         \n",
            "               no_dropout: True                          \n",
            "                  no_flip: False                         \n",
            "                  no_html: False                         \n",
            "                    normD: instance                      \n",
            "                    normG: instance                      \n",
            "              num_patches: 256                           \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: train                         \n",
            "                pool_size: 0                             \n",
            "               preprocess: resize_and_crop               \n",
            "          pretrained_name: None                          \n",
            "               print_freq: 100                           \n",
            "             save_by_iter: False                         \n",
            "          save_epoch_freq: 5                             \n",
            "         save_latest_freq: 5000                          \n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "         update_html_freq: 1000                          \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [UnalignedDataset] was created\n",
            "model [CUTModel] was created\n",
            "The number of training images = 214\n",
            "Setting up a new session...\n",
            "Exception in user code:\n",
            "------------------------------------------------------------\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/urllib3/connection.py\", line 159, in _new_conn\n",
            "    (self._dns_host, self.port), self.timeout, **extra_kw)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/urllib3/util/connection.py\", line 80, in create_connection\n",
            "    raise err\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/urllib3/util/connection.py\", line 70, in create_connection\n",
            "    sock.connect(sa)\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py\", line 600, in urlopen\n",
            "    chunked=chunked)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py\", line 354, in _make_request\n",
            "    conn.request(method, url, **httplib_request_kw)\n",
            "  File \"/usr/lib/python3.6/http/client.py\", line 1264, in request\n",
            "    self._send_request(method, url, body, headers, encode_chunked)\n",
            "  File \"/usr/lib/python3.6/http/client.py\", line 1310, in _send_request\n",
            "    self.endheaders(body, encode_chunked=encode_chunked)\n",
            "  File \"/usr/lib/python3.6/http/client.py\", line 1259, in endheaders\n",
            "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
            "  File \"/usr/lib/python3.6/http/client.py\", line 1038, in _send_output\n",
            "    self.send(msg)\n",
            "  File \"/usr/lib/python3.6/http/client.py\", line 976, in send\n",
            "    self.connect()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/urllib3/connection.py\", line 181, in connect\n",
            "    conn = self._new_conn()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/urllib3/connection.py\", line 168, in _new_conn\n",
            "    self, \"Failed to establish a new connection: %s\" % e)\n",
            "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fdc3ab4c6a0>: Failed to establish a new connection: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/requests/adapters.py\", line 449, in send\n",
            "    timeout=timeout\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py\", line 638, in urlopen\n",
            "    _stacktrace=sys.exc_info()[2])\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/urllib3/util/retry.py\", line 399, in increment\n",
            "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
            "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /env/main (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fdc3ab4c6a0>: Failed to establish a new connection: [Errno 111] Connection refused',))\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/visdom/__init__.py\", line 711, in _send\n",
            "    data=json.dumps(msg),\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/visdom/__init__.py\", line 677, in _handle_post\n",
            "    r = self.session.post(url, data=data)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/requests/sessions.py\", line 578, in post\n",
            "    return self.request('POST', url, data=data, json=json, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/requests/sessions.py\", line 530, in request\n",
            "    resp = self.send(prep, **send_kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/requests/sessions.py\", line 643, in send\n",
            "    r = adapter.send(request, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/requests/adapters.py\", line 516, in send\n",
            "    raise ConnectionError(e, request=request)\n",
            "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /env/main (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fdc3ab4c6a0>: Failed to establish a new connection: [Errno 111] Connection refused',))\n",
            "[Errno 99] Cannot assign requested address\n",
            "[Errno 99] Cannot assign requested address\n",
            "[Errno 99] Cannot assign requested address\n",
            "Visdom python client failed to establish socket to get messages from the server. This feature is optional and can be disabled by initializing Visdom with `use_incoming_socket=False`, which will prevent waiting for this request to timeout.\n",
            "\n",
            "\n",
            "Could not connect to Visdom server. \n",
            " Trying to start a server....\n",
            "Command: /usr/bin/python3 -m visdom.server -p 8097 &>/dev/null &\n",
            "create web directory ./checkpoints/grumpycat_CUT/web...\n",
            "[W TensorIterator.cpp:924] Warning: Mixed memory format inputs detected while calling the operator. The operator will output channels_last tensor even if some of the inputs are not in channels_last format. (function operator())\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 11.378 M\n",
            "[Network F] Total number of parameters : 0.560 M\n",
            "[Network D] Total number of parameters : 2.765 M\n",
            "-----------------------------------------------\n",
            "(epoch: 1, iters: 100, time: 0.168, data: 0.131) G_GAN: 0.277 D_real: 0.269 D_fake: 0.226 G: 3.697 NCE: 3.431 NCE_Y: 3.409 \n",
            "(epoch: 1, iters: 200, time: 0.199, data: 0.001) G_GAN: 0.256 D_real: 0.237 D_fake: 0.206 G: 2.959 NCE: 2.463 NCE_Y: 2.942 \n",
            "End of epoch 1 / 400 \t Time Taken: 56 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 2, iters: 86, time: 0.217, data: 0.001) G_GAN: 0.369 D_real: 0.310 D_fake: 0.131 G: 2.512 NCE: 2.148 NCE_Y: 2.139 \n",
            "(epoch: 2, iters: 186, time: 0.228, data: 0.002) G_GAN: 0.363 D_real: 0.273 D_fake: 0.145 G: 2.012 NCE: 1.592 NCE_Y: 1.706 \n",
            "End of epoch 2 / 400 \t Time Taken: 53 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 3, iters: 72, time: 0.236, data: 0.001) G_GAN: 0.530 D_real: 0.328 D_fake: 0.435 G: 2.053 NCE: 1.623 NCE_Y: 1.423 \n",
            "(epoch: 3, iters: 172, time: 0.240, data: 0.001) G_GAN: 0.357 D_real: 0.071 D_fake: 0.272 G: 1.969 NCE: 1.644 NCE_Y: 1.578 \n",
            "End of epoch 3 / 400 \t Time Taken: 53 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 4, iters: 58, time: 0.242, data: 0.001) G_GAN: 0.439 D_real: 0.243 D_fake: 0.201 G: 2.081 NCE: 1.550 NCE_Y: 1.736 \n",
            "(epoch: 4, iters: 158, time: 0.244, data: 0.001) G_GAN: 0.437 D_real: 0.102 D_fake: 0.265 G: 1.936 NCE: 1.539 NCE_Y: 1.460 \n",
            "End of epoch 4 / 400 \t Time Taken: 53 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 5, iters: 44, time: 0.245, data: 0.001) G_GAN: 0.575 D_real: 0.070 D_fake: 0.359 G: 2.264 NCE: 1.754 NCE_Y: 1.623 \n",
            "(epoch: 5, iters: 144, time: 0.246, data: 0.001) G_GAN: 0.518 D_real: 0.199 D_fake: 0.063 G: 2.016 NCE: 1.640 NCE_Y: 1.356 \n",
            "saving the model at the end of epoch 5, iters 1070\n",
            "End of epoch 5 / 400 \t Time Taken: 53 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 6, iters: 30, time: 0.246, data: 0.002) G_GAN: 0.367 D_real: 0.263 D_fake: 0.208 G: 1.764 NCE: 1.499 NCE_Y: 1.296 \n",
            "(epoch: 6, iters: 130, time: 0.246, data: 0.001) G_GAN: 0.345 D_real: 0.202 D_fake: 0.229 G: 1.784 NCE: 1.470 NCE_Y: 1.409 \n",
            "End of epoch 6 / 400 \t Time Taken: 53 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 7, iters: 16, time: 0.246, data: 0.001) G_GAN: 0.326 D_real: 0.336 D_fake: 0.103 G: 1.689 NCE: 1.604 NCE_Y: 1.124 \n",
            "(epoch: 7, iters: 116, time: 0.246, data: 0.001) G_GAN: 0.603 D_real: 0.225 D_fake: 0.223 G: 1.958 NCE: 1.441 NCE_Y: 1.270 \n",
            "End of epoch 7 / 400 \t Time Taken: 53 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 8, iters: 2, time: 0.246, data: 0.001) G_GAN: 0.404 D_real: 0.192 D_fake: 0.278 G: 1.639 NCE: 1.370 NCE_Y: 1.100 \n",
            "(epoch: 8, iters: 102, time: 0.247, data: 0.000) G_GAN: 0.316 D_real: 0.230 D_fake: 0.250 G: 1.767 NCE: 1.573 NCE_Y: 1.329 \n",
            "(epoch: 8, iters: 202, time: 0.247, data: 0.001) G_GAN: 0.399 D_real: 0.101 D_fake: 0.255 G: 1.675 NCE: 1.362 NCE_Y: 1.188 \n",
            "End of epoch 8 / 400 \t Time Taken: 53 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 9, iters: 88, time: 0.247, data: 0.001) G_GAN: 0.355 D_real: 0.196 D_fake: 0.188 G: 1.632 NCE: 1.407 NCE_Y: 1.148 \n",
            "(epoch: 9, iters: 188, time: 0.247, data: 0.001) G_GAN: 0.374 D_real: 0.358 D_fake: 0.147 G: 1.459 NCE: 1.173 NCE_Y: 0.997 \n",
            "End of epoch 9 / 400 \t Time Taken: 53 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 10, iters: 74, time: 0.247, data: 0.001) G_GAN: 0.427 D_real: 0.156 D_fake: 0.392 G: 1.644 NCE: 1.382 NCE_Y: 1.052 \n",
            "(epoch: 10, iters: 174, time: 0.247, data: 0.001) G_GAN: 0.343 D_real: 0.180 D_fake: 0.148 G: 1.688 NCE: 1.582 NCE_Y: 1.107 \n",
            "saving the model at the end of epoch 10, iters 2140\n",
            "End of epoch 10 / 400 \t Time Taken: 53 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 11, iters: 60, time: 0.247, data: 0.001) G_GAN: 0.262 D_real: 0.405 D_fake: 0.206 G: 1.535 NCE: 1.396 NCE_Y: 1.149 \n",
            "(epoch: 11, iters: 160, time: 0.247, data: 0.001) G_GAN: 0.364 D_real: 0.564 D_fake: 0.109 G: 1.461 NCE: 1.189 NCE_Y: 1.004 \n",
            "End of epoch 11 / 400 \t Time Taken: 53 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 12, iters: 46, time: 0.247, data: 0.001) G_GAN: 0.293 D_real: 0.201 D_fake: 0.217 G: 1.413 NCE: 1.277 NCE_Y: 0.963 \n",
            "(epoch: 12, iters: 146, time: 0.247, data: 0.001) G_GAN: 0.422 D_real: 0.128 D_fake: 0.211 G: 1.601 NCE: 1.262 NCE_Y: 1.096 \n",
            "End of epoch 12 / 400 \t Time Taken: 53 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 13, iters: 32, time: 0.247, data: 0.002) G_GAN: 0.382 D_real: 0.264 D_fake: 0.175 G: 1.453 NCE: 1.206 NCE_Y: 0.936 \n",
            "(epoch: 13, iters: 132, time: 0.247, data: 0.001) G_GAN: 0.358 D_real: 0.301 D_fake: 0.225 G: 1.682 NCE: 1.295 NCE_Y: 1.353 \n",
            "End of epoch 13 / 400 \t Time Taken: 53 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 14, iters: 18, time: 0.247, data: 0.001) G_GAN: 0.311 D_real: 0.150 D_fake: 0.432 G: 1.415 NCE: 1.272 NCE_Y: 0.937 \n",
            "(epoch: 14, iters: 118, time: 0.247, data: 0.001) G_GAN: 0.362 D_real: 0.127 D_fake: 0.326 G: 1.434 NCE: 1.189 NCE_Y: 0.955 \n",
            "End of epoch 14 / 400 \t Time Taken: 53 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 15, iters: 4, time: 0.247, data: 0.001) G_GAN: 0.468 D_real: 0.055 D_fake: 0.276 G: 1.582 NCE: 1.203 NCE_Y: 1.024 \n",
            "(epoch: 15, iters: 104, time: 0.247, data: 0.000) G_GAN: 0.244 D_real: 0.356 D_fake: 0.237 G: 1.406 NCE: 1.279 NCE_Y: 1.044 \n",
            "(epoch: 15, iters: 204, time: 0.247, data: 0.001) G_GAN: 0.183 D_real: 0.439 D_fake: 0.195 G: 1.210 NCE: 1.167 NCE_Y: 0.887 \n",
            "saving the model at the end of epoch 15, iters 3210\n",
            "End of epoch 15 / 400 \t Time Taken: 54 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 16, iters: 90, time: 0.247, data: 0.002) G_GAN: 0.324 D_real: 0.321 D_fake: 0.214 G: 1.464 NCE: 1.274 NCE_Y: 1.005 \n",
            "(epoch: 16, iters: 190, time: 0.247, data: 0.001) G_GAN: 0.902 D_real: 0.226 D_fake: 0.249 G: 1.872 NCE: 0.988 NCE_Y: 0.952 \n",
            "End of epoch 16 / 400 \t Time Taken: 53 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 17, iters: 76, time: 0.247, data: 0.002) G_GAN: 0.363 D_real: 0.241 D_fake: 0.151 G: 1.445 NCE: 1.197 NCE_Y: 0.967 \n",
            "(epoch: 17, iters: 176, time: 0.247, data: 0.001) G_GAN: 0.656 D_real: 0.048 D_fake: 0.460 G: 1.695 NCE: 1.130 NCE_Y: 0.949 \n",
            "End of epoch 17 / 400 \t Time Taken: 53 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 18, iters: 62, time: 0.247, data: 0.001) G_GAN: 0.338 D_real: 0.324 D_fake: 0.159 G: 1.385 NCE: 1.199 NCE_Y: 0.896 \n",
            "(epoch: 18, iters: 162, time: 0.247, data: 0.001) G_GAN: 0.494 D_real: 0.085 D_fake: 0.355 G: 1.595 NCE: 1.324 NCE_Y: 0.878 \n",
            "End of epoch 18 / 400 \t Time Taken: 53 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 19, iters: 48, time: 0.247, data: 0.001) G_GAN: 0.501 D_real: 0.120 D_fake: 0.224 G: 1.548 NCE: 1.148 NCE_Y: 0.947 \n",
            "(epoch: 19, iters: 148, time: 0.247, data: 0.001) G_GAN: 0.417 D_real: 0.159 D_fake: 0.226 G: 1.505 NCE: 1.245 NCE_Y: 0.932 \n",
            "End of epoch 19 / 400 \t Time Taken: 53 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 20, iters: 34, time: 0.247, data: 0.001) G_GAN: 0.390 D_real: 0.148 D_fake: 0.194 G: 1.510 NCE: 1.321 NCE_Y: 0.919 \n",
            "(epoch: 20, iters: 134, time: 0.247, data: 0.001) G_GAN: 0.326 D_real: 0.129 D_fake: 0.351 G: 1.417 NCE: 1.238 NCE_Y: 0.944 \n",
            "saving the model at the end of epoch 20, iters 4280\n",
            "End of epoch 20 / 400 \t Time Taken: 53 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 21, iters: 20, time: 0.247, data: 0.001) G_GAN: 0.256 D_real: 0.216 D_fake: 0.344 G: 1.435 NCE: 1.390 NCE_Y: 0.969 \n",
            "(epoch: 21, iters: 120, time: 0.247, data: 0.001) G_GAN: 0.627 D_real: 0.061 D_fake: 0.297 G: 1.668 NCE: 1.163 NCE_Y: 0.919 \n",
            "End of epoch 21 / 400 \t Time Taken: 53 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 22, iters: 6, time: 0.247, data: 0.001) G_GAN: 0.460 D_real: 0.281 D_fake: 0.287 G: 1.588 NCE: 1.278 NCE_Y: 0.977 \n",
            "(epoch: 22, iters: 106, time: 0.247, data: 0.002) G_GAN: 0.612 D_real: 0.115 D_fake: 0.219 G: 1.639 NCE: 1.147 NCE_Y: 0.906 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbBSlniqPEiK",
        "colab_type": "text"
      },
      "source": [
        "##Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vgnZhxLOEHf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}