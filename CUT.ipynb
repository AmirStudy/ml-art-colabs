{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CUT.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNQPTP0J/4PBmhXIg7lRaoR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dvschultz/ml-art-colabs/blob/master/CUT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVR4bEt9Ptel",
        "colab_type": "text"
      },
      "source": [
        "#CUT\n",
        "This new model uses contrastive learning (the hot technique of the moment) to better train unaligned image to image translation (i.e CycleGAN)\n",
        "\n",
        "[GitHub](https://github.com/taesungp/contrastive-unpaired-translation)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHt7jlAPKw2l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "206420e2-1364-4962-c285-e8b157cc2443"
      },
      "source": [
        "!git clone https://github.com/taesungp/contrastive-unpaired-translation CUT\n",
        "!pip install dominate>=2.4.0 visdom>=0.1.8.8 GPUtil>=1.4.0\n",
        "%cd CUT"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'CUT'...\n",
            "remote: Enumerating objects: 178, done.\u001b[K\n",
            "remote: Counting objects: 100% (178/178), done.\u001b[K\n",
            "remote: Compressing objects: 100% (131/131), done.\u001b[K\n",
            "remote: Total 178 (delta 77), reused 142 (delta 44), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (178/178), 17.04 MiB | 36.65 MiB/s, done.\n",
            "Resolving deltas: 100% (77/77), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRI0XL6xK386",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!bash ./datasets/download_cut_dataset.sh grumpifycat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1tdZoGaMOGf",
        "colab_type": "text"
      },
      "source": [
        "## Train\n",
        "Create a folder in `./datasets` and put two folders inside it. `trainA` should contain images from one domain and `trainB` should contain images from another domain. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_npjQWxMjkr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_path = './datasets/grumpifycat'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WEJ3xy9K8ck",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d267181d-bea3-46e4-95e3-f6c840f34072"
      },
      "source": [
        "!python train.py --dataroot ./datasets/grumpifycat --name grumpycat_CUT --CUT_mode CUT"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------- Options ---------------\n",
            "                 CUT_mode: CUT                           \n",
            "               batch_size: 1                             \n",
            "                    beta1: 0.5                           \n",
            "                    beta2: 0.999                         \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "           continue_train: False                         \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ./datasets/grumpifycat        \t[default: placeholder]\n",
            "             dataset_mode: unaligned                     \n",
            "                direction: AtoB                          \n",
            "              display_env: main                          \n",
            "             display_freq: 400                           \n",
            "               display_id: None                          \n",
            "            display_ncols: 4                             \n",
            "             display_port: 8097                          \n",
            "           display_server: http://localhost              \n",
            "          display_winsize: 256                           \n",
            "               easy_label: experiment_name               \n",
            "                    epoch: latest                        \n",
            "              epoch_count: 1                             \n",
            "          evaluation_freq: 5000                          \n",
            "        flip_equivariance: False                         \n",
            "                 gan_mode: lsgan                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: xavier                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: True                          \t[default: None]\n",
            "               lambda_GAN: 1.0                           \n",
            "               lambda_NCE: 1.0                           \n",
            "                load_size: 286                           \n",
            "                       lr: 0.0002                        \n",
            "           lr_decay_iters: 50                            \n",
            "                lr_policy: linear                        \n",
            "         max_dataset_size: inf                           \n",
            "                    model: cut                           \n",
            "                 n_epochs: 200                           \n",
            "           n_epochs_decay: 200                           \n",
            "               n_layers_D: 3                             \n",
            "                     name: grumpycat_CUT                 \t[default: experiment_name]\n",
            "                    nce_T: 0.07                          \n",
            "                  nce_idt: True                          \n",
            "               nce_layers: 0,4,8,12,16                   \n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netF: mlp_sample                    \n",
            "                  netF_nc: 256                           \n",
            "                     netG: resnet_9blocks                \n",
            "                      ngf: 64                            \n",
            "             no_antialias: False                         \n",
            "          no_antialias_up: False                         \n",
            "               no_dropout: True                          \n",
            "                  no_flip: False                         \n",
            "                  no_html: False                         \n",
            "                    normD: instance                      \n",
            "                    normG: instance                      \n",
            "              num_patches: 256                           \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: train                         \n",
            "                pool_size: 0                             \n",
            "               preprocess: resize_and_crop               \n",
            "          pretrained_name: None                          \n",
            "               print_freq: 100                           \n",
            "             save_by_iter: False                         \n",
            "          save_epoch_freq: 5                             \n",
            "         save_latest_freq: 5000                          \n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "         update_html_freq: 1000                          \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [UnalignedDataset] was created\n",
            "model [CUTModel] was created\n",
            "The number of training images = 214\n",
            "Setting up a new session...\n",
            "Exception in user code:\n",
            "------------------------------------------------------------\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/urllib3/connection.py\", line 159, in _new_conn\n",
            "    (self._dns_host, self.port), self.timeout, **extra_kw)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/urllib3/util/connection.py\", line 80, in create_connection\n",
            "    raise err\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/urllib3/util/connection.py\", line 70, in create_connection\n",
            "    sock.connect(sa)\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py\", line 600, in urlopen\n",
            "    chunked=chunked)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py\", line 354, in _make_request\n",
            "    conn.request(method, url, **httplib_request_kw)\n",
            "  File \"/usr/lib/python3.6/http/client.py\", line 1264, in request\n",
            "    self._send_request(method, url, body, headers, encode_chunked)\n",
            "  File \"/usr/lib/python3.6/http/client.py\", line 1310, in _send_request\n",
            "    self.endheaders(body, encode_chunked=encode_chunked)\n",
            "  File \"/usr/lib/python3.6/http/client.py\", line 1259, in endheaders\n",
            "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
            "  File \"/usr/lib/python3.6/http/client.py\", line 1038, in _send_output\n",
            "    self.send(msg)\n",
            "  File \"/usr/lib/python3.6/http/client.py\", line 976, in send\n",
            "    self.connect()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/urllib3/connection.py\", line 181, in connect\n",
            "    conn = self._new_conn()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/urllib3/connection.py\", line 168, in _new_conn\n",
            "    self, \"Failed to establish a new connection: %s\" % e)\n",
            "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fdc3ab4c6a0>: Failed to establish a new connection: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/requests/adapters.py\", line 449, in send\n",
            "    timeout=timeout\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py\", line 638, in urlopen\n",
            "    _stacktrace=sys.exc_info()[2])\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/urllib3/util/retry.py\", line 399, in increment\n",
            "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
            "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /env/main (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fdc3ab4c6a0>: Failed to establish a new connection: [Errno 111] Connection refused',))\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/visdom/__init__.py\", line 711, in _send\n",
            "    data=json.dumps(msg),\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/visdom/__init__.py\", line 677, in _handle_post\n",
            "    r = self.session.post(url, data=data)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/requests/sessions.py\", line 578, in post\n",
            "    return self.request('POST', url, data=data, json=json, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/requests/sessions.py\", line 530, in request\n",
            "    resp = self.send(prep, **send_kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/requests/sessions.py\", line 643, in send\n",
            "    r = adapter.send(request, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/requests/adapters.py\", line 516, in send\n",
            "    raise ConnectionError(e, request=request)\n",
            "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /env/main (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fdc3ab4c6a0>: Failed to establish a new connection: [Errno 111] Connection refused',))\n",
            "[Errno 99] Cannot assign requested address\n",
            "[Errno 99] Cannot assign requested address\n",
            "[Errno 99] Cannot assign requested address\n",
            "Visdom python client failed to establish socket to get messages from the server. This feature is optional and can be disabled by initializing Visdom with `use_incoming_socket=False`, which will prevent waiting for this request to timeout.\n",
            "\n",
            "\n",
            "Could not connect to Visdom server. \n",
            " Trying to start a server....\n",
            "Command: /usr/bin/python3 -m visdom.server -p 8097 &>/dev/null &\n",
            "create web directory ./checkpoints/grumpycat_CUT/web...\n",
            "[W TensorIterator.cpp:924] Warning: Mixed memory format inputs detected while calling the operator. The operator will output channels_last tensor even if some of the inputs are not in channels_last format. (function operator())\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 11.378 M\n",
            "[Network F] Total number of parameters : 0.560 M\n",
            "[Network D] Total number of parameters : 2.765 M\n",
            "-----------------------------------------------\n",
            "(epoch: 1, iters: 100, time: 0.168, data: 0.131) G_GAN: 0.277 D_real: 0.269 D_fake: 0.226 G: 3.697 NCE: 3.431 NCE_Y: 3.409 \n",
            "(epoch: 1, iters: 200, time: 0.199, data: 0.001) G_GAN: 0.256 D_real: 0.237 D_fake: 0.206 G: 2.959 NCE: 2.463 NCE_Y: 2.942 \n",
            "End of epoch 1 / 400 \t Time Taken: 56 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 2, iters: 86, time: 0.217, data: 0.001) G_GAN: 0.369 D_real: 0.310 D_fake: 0.131 G: 2.512 NCE: 2.148 NCE_Y: 2.139 \n",
            "(epoch: 2, iters: 186, time: 0.228, data: 0.002) G_GAN: 0.363 D_real: 0.273 D_fake: 0.145 G: 2.012 NCE: 1.592 NCE_Y: 1.706 \n",
            "End of epoch 2 / 400 \t Time Taken: 53 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 3, iters: 72, time: 0.236, data: 0.001) G_GAN: 0.530 D_real: 0.328 D_fake: 0.435 G: 2.053 NCE: 1.623 NCE_Y: 1.423 \n",
            "(epoch: 3, iters: 172, time: 0.240, data: 0.001) G_GAN: 0.357 D_real: 0.071 D_fake: 0.272 G: 1.969 NCE: 1.644 NCE_Y: 1.578 \n",
            "End of epoch 3 / 400 \t Time Taken: 53 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 4, iters: 58, time: 0.242, data: 0.001) G_GAN: 0.439 D_real: 0.243 D_fake: 0.201 G: 2.081 NCE: 1.550 NCE_Y: 1.736 \n",
            "(epoch: 4, iters: 158, time: 0.244, data: 0.001) G_GAN: 0.437 D_real: 0.102 D_fake: 0.265 G: 1.936 NCE: 1.539 NCE_Y: 1.460 \n",
            "End of epoch 4 / 400 \t Time Taken: 53 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 5, iters: 44, time: 0.245, data: 0.001) G_GAN: 0.575 D_real: 0.070 D_fake: 0.359 G: 2.264 NCE: 1.754 NCE_Y: 1.623 \n",
            "(epoch: 5, iters: 144, time: 0.246, data: 0.001) G_GAN: 0.518 D_real: 0.199 D_fake: 0.063 G: 2.016 NCE: 1.640 NCE_Y: 1.356 \n",
            "saving the model at the end of epoch 5, iters 1070\n",
            "End of epoch 5 / 400 \t Time Taken: 53 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 6, iters: 30, time: 0.246, data: 0.002) G_GAN: 0.367 D_real: 0.263 D_fake: 0.208 G: 1.764 NCE: 1.499 NCE_Y: 1.296 \n",
            "(epoch: 6, iters: 130, time: 0.246, data: 0.001) G_GAN: 0.345 D_real: 0.202 D_fake: 0.229 G: 1.784 NCE: 1.470 NCE_Y: 1.409 \n",
            "End of epoch 6 / 400 \t Time Taken: 53 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 7, iters: 16, time: 0.246, data: 0.001) G_GAN: 0.326 D_real: 0.336 D_fake: 0.103 G: 1.689 NCE: 1.604 NCE_Y: 1.124 \n",
            "(epoch: 7, iters: 116, time: 0.246, data: 0.001) G_GAN: 0.603 D_real: 0.225 D_fake: 0.223 G: 1.958 NCE: 1.441 NCE_Y: 1.270 \n",
            "End of epoch 7 / 400 \t Time Taken: 53 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 8, iters: 2, time: 0.246, data: 0.001) G_GAN: 0.404 D_real: 0.192 D_fake: 0.278 G: 1.639 NCE: 1.370 NCE_Y: 1.100 \n",
            "(epoch: 8, iters: 102, time: 0.247, data: 0.000) G_GAN: 0.316 D_real: 0.230 D_fake: 0.250 G: 1.767 NCE: 1.573 NCE_Y: 1.329 \n",
            "(epoch: 8, iters: 202, time: 0.247, data: 0.001) G_GAN: 0.399 D_real: 0.101 D_fake: 0.255 G: 1.675 NCE: 1.362 NCE_Y: 1.188 \n",
            "End of epoch 8 / 400 \t Time Taken: 53 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 9, iters: 88, time: 0.247, data: 0.001) G_GAN: 0.355 D_real: 0.196 D_fake: 0.188 G: 1.632 NCE: 1.407 NCE_Y: 1.148 \n",
            "(epoch: 9, iters: 188, time: 0.247, data: 0.001) G_GAN: 0.374 D_real: 0.358 D_fake: 0.147 G: 1.459 NCE: 1.173 NCE_Y: 0.997 \n",
            "End of epoch 9 / 400 \t Time Taken: 53 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 10, iters: 74, time: 0.247, data: 0.001) G_GAN: 0.427 D_real: 0.156 D_fake: 0.392 G: 1.644 NCE: 1.382 NCE_Y: 1.052 \n",
            "(epoch: 10, iters: 174, time: 0.247, data: 0.001) G_GAN: 0.343 D_real: 0.180 D_fake: 0.148 G: 1.688 NCE: 1.582 NCE_Y: 1.107 \n",
            "saving the model at the end of epoch 10, iters 2140\n",
            "End of epoch 10 / 400 \t Time Taken: 53 sec\n",
            "learning rate = 0.0002000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbBSlniqPEiK",
        "colab_type": "text"
      },
      "source": [
        "##Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vgnZhxLOEHf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}